{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Example\n",
    "## No hidden layer ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#sigmoid function\n",
    "def nonlin(x,deriv = False):\n",
    "    if (deriv == True):\n",
    "        return x * (1 - x)\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input dataset\n",
    "X = np.array([\n",
    "        [0,0,1],\n",
    "        [0,1,1],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "             ])\n",
    "\n",
    "# output dataset\n",
    "y = np.array([[0,0,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "[[ 0.00966781]\n",
      " [ 0.00786381]\n",
      " [ 0.99359062]\n",
      " [ 0.99211763]]\n"
     ]
    }
   ],
   "source": [
    "# seed random number to start calculation\n",
    "# deterministic\n",
    "np.random.seed(1030)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = 2 * np.random.random((3,1)) - 1\n",
    "\n",
    "for iter in xrange(10000):\n",
    "    # forward propagation\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))\n",
    "    \n",
    "    # how much did weight miss\n",
    "    l1_error = y - l1\n",
    "    \n",
    "    # multiply how much weight missed by the slope of the sigmoid at the values in l1\n",
    "    l1_delta = l1_error * nonlin(l1,True)\n",
    "    \n",
    "    #update weights\n",
    "    syn0 += np.dot(l0.T, l1_delta)\n",
    "    \n",
    "print 'Output After Training:'\n",
    "print l1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Example\n",
    "## One hidden layer ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def nonlin(x,deriv = False):\n",
    "    if (deriv == True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input dataset\n",
    "X = np.array([\n",
    "        [0,0,1],\n",
    "        [0,1,1],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "             ])\n",
    "\n",
    "# output dataset\n",
    "y = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:0.500722751734\n",
      "Error:0.00944423263148\n",
      "Error:0.00645451300598\n",
      "Error:0.00520328533237\n",
      "Error:0.00447524466286\n",
      "Error:0.00398526960138\n",
      "Output After Training:\n",
      "[[ 0.00377867]\n",
      " [ 0.99607282]\n",
      " [ 0.99642215]\n",
      " [ 0.00322397]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1030)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = 2 * np.random.random((3,4)) - 1\n",
    "syn1 = 2 * np.random.random((4,1)) - 1\n",
    "\n",
    "for j in xrange(60000):\n",
    "    # forward propagation\n",
    "    l0 = X\n",
    "    l1 = nonlin(np.dot(l0,syn0))    \n",
    "    l2 = nonlin(np.dot(l1,syn1))\n",
    "    \n",
    "    # how much did weight miss\n",
    "    l2_error = y - l2\n",
    "    \n",
    "    # show training progress\n",
    "    if (j % 10000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(l2_error)))\n",
    "        \n",
    "    l2_delta = l2_error * nonlin(l2,True)\n",
    "    \n",
    "    l1_error = l2_delta.dot(syn1.T)\n",
    "    \n",
    "    l1_delta = l1_error * nonlin(l1,True)\n",
    "    \n",
    "    syn1 += l1.T.dot(l2_delta)\n",
    "    syn0 += l0.T.dot(l1_delta)\n",
    "    \n",
    "    \n",
    "print 'Output After Training:'\n",
    "print l2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def nonlin(x,deriv = False):\n",
    "    if (deriv == True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input dataset\n",
    "X = np.array([\n",
    "        [0,0,1],\n",
    "        [0,1,1],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "             ])\n",
    "\n",
    "# output dataset\n",
    "\n",
    "y = np.array([[0,1,1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training With Alpha:0.001\n",
      "Error after 0 iteratios:0.500722751734\n",
      "Error after 10000 iteratios:0.500541492509\n",
      "Error after 20000 iteratios:0.500383825972\n",
      "Error after 30000 iteratios:0.500255238651\n",
      "Error after 40000 iteratios:0.500144928598\n",
      "Error after 50000 iteratios:0.500044559456\n",
      "Output After Training:\n",
      "[[ 0.51801399]\n",
      " [ 0.48130721]\n",
      " [ 0.52450394]\n",
      " [ 0.48758856]]\n",
      "\n",
      "Training With Alpha:0.01\n",
      "Error after 0 iteratios:0.500722751734\n",
      "Error after 10000 iteratios:0.499495969632\n",
      "Error after 20000 iteratios:0.493923014575\n",
      "Error after 30000 iteratios:0.423222529413\n",
      "Error after 40000 iteratios:0.215490950025\n",
      "Error after 50000 iteratios:0.124592080743\n",
      "Output After Training:\n",
      "[[ 0.08588755]\n",
      " [ 0.91131955]\n",
      " [ 0.89339436]\n",
      " [ 0.08130021]]\n",
      "\n",
      "Training With Alpha:0.1\n",
      "Error after 0 iteratios:0.500722751734\n",
      "Error after 10000 iteratios:0.0482125985408\n",
      "Error after 20000 iteratios:0.0263339106834\n",
      "Error after 30000 iteratios:0.0197018971925\n",
      "Error after 40000 iteratios:0.0163078069019\n",
      "Error after 50000 iteratios:0.0141826454915\n",
      "Output After Training:\n",
      "[[ 0.01300557]\n",
      " [ 0.98660341]\n",
      " [ 0.98633112]\n",
      " [ 0.01072864]]\n",
      "\n",
      "Training With Alpha:1\n",
      "Error after 0 iteratios:0.500722751734\n",
      "Error after 10000 iteratios:0.00944423263148\n",
      "Error after 20000 iteratios:0.00645451300598\n",
      "Error after 30000 iteratios:0.00520328533237\n",
      "Error after 40000 iteratios:0.00447524466286\n",
      "Error after 50000 iteratios:0.00398526960138\n",
      "Output After Training:\n",
      "[[ 0.00377867]\n",
      " [ 0.99607282]\n",
      " [ 0.99642215]\n",
      " [ 0.00322397]]\n",
      "\n",
      "Training With Alpha:10\n",
      "Error after 0 iteratios:0.500722751734\n",
      "Error after 10000 iteratios:0.00288106086083\n",
      "Error after 20000 iteratios:0.00201836995857\n",
      "Error after 30000 iteratios:0.0016406084995\n",
      "Error after 40000 iteratios:0.00141674978092\n",
      "Error after 50000 iteratios:0.00126457087369\n",
      "Output After Training:\n",
      "[[ 0.00115887]\n",
      " [ 0.9987038 ]\n",
      " [ 0.99898101]\n",
      " [ 0.0011362 ]]\n",
      "\n",
      "Training With Alpha:100\n",
      "Error after 0 iteratios:0.500722751734\n",
      "Error after 10000 iteratios:0.375245668204\n",
      "Error after 20000 iteratios:0.375172238097\n",
      "Error after 30000 iteratios:0.375139983065\n",
      "Error after 40000 iteratios:0.375120849927\n",
      "Error after 50000 iteratios:0.375107837797\n",
      "Output After Training:\n",
      "[[  3.91771492e-04]\n",
      " [  4.99999305e-01]\n",
      " [  4.99999432e-01]\n",
      " [  5.00000000e-01]]\n",
      "\n",
      "Training With Alpha:1000\n",
      "Error after 0 iteratios:0.500722751734\n",
      "Error after 10000 iteratios:0.499999999813\n",
      "Error after 20000 iteratios:0.499999999812\n",
      "Error after 30000 iteratios:0.499999999811\n",
      "Error after 40000 iteratios:0.49999999981\n",
      "Error after 50000 iteratios:0.49999999981\n",
      "Output After Training:\n",
      "[[ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]\n",
      " [ 0.5]]\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.001,0.01,0.1,1,10,100,1000]\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "    print \"\\nTraining With Alpha:\"+str(alpha)\n",
    "    \n",
    "    np.random.seed(1030)\n",
    "\n",
    "    # initialize weights randomly with mean 0\n",
    "    syn0 = 2 * np.random.random((3,4)) - 1\n",
    "    syn1 = 2 * np.random.random((4,1)) - 1\n",
    "\n",
    "    for j in xrange(60000):\n",
    "        # forward propagation\n",
    "        l0 = X\n",
    "        l1 = nonlin(np.dot(l0,syn0))    \n",
    "        l2 = nonlin(np.dot(l1,syn1))\n",
    "\n",
    "        # how much did weight miss\n",
    "        l2_error = y - l2\n",
    "\n",
    "        # show training progress\n",
    "        if (j % 10000) == 0:\n",
    "            print \"Error after \"+str(j) +\" iteratios:\" + str(np.mean(np.abs(l2_error)))\n",
    "\n",
    "        l2_delta = l2_error * nonlin(l2,True)\n",
    "\n",
    "        l1_error = l2_delta.dot(syn1.T)\n",
    "\n",
    "        l1_delta = l1_error * nonlin(l1,True)\n",
    "\n",
    "        syn1 += alpha*(l1.T.dot(l2_delta))\n",
    "        syn0 += alpha*(l0.T.dot(l1_delta))\n",
    "\n",
    "\n",
    "    print 'Output After Training:'\n",
    "    print l2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
